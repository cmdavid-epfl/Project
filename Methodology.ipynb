{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Story Outline\n",
    "\n",
    "## Part 1. The Big Picture\n",
    "\n",
    "In this first part, we answer the following questions:\n",
    "- What does the typical patent-holder look like today, and how has that evolved between today and the 1990's?\n",
    "- Is a migration of innovators through time visible in the data, e.g. a convergence towards certain innovation centers?\n",
    "- How has the number of assignees and inventors evolved in this period?\n",
    "\n",
    "The goal here is to address the main issue that brought us to chose this subject for our data story, by clearly showing how innovation today transcends geographies.\n",
    "\n",
    "### Approach\n",
    "\n",
    "This first part focuses on how data evolves through time from a geographic standpoint, and we decided that using maps to visualize this evolution would be the best approach. As we have access to clean longitude and latitude data (see the below section **Data Gathering**), using the **[Folium](https://python-visualization.github.io/folium/docs-v0.6.0/)** library, which has e.g. cluster-functionality using it's heat map plugin, was found to be the best way to quantify the magnitude of the networks in different geographic zones. One challenge was to show the evolution throughout the entire time period in an intuitive way. While we first thought about using Folium's layer control so that the user could manually toggle between years, for the purposes of telling a data story, we judged that it would make the story more fluid to use a timelapse. The method we used to realize this is detailed in the below section **Visualizations**.  \n",
    "\n",
    "A few time series were also plotted to provide a more quantitative perspective on the data, to be more certain about the conclusions we drew from the figures.\n",
    "    \n",
    "\n",
    "## Part 2. Peeling back the layers\n",
    "\n",
    "In this second part, we look at the following examples of innovation networks for specific patents held by the following specific assignees:\n",
    "- companies : \n",
    "  - patents :\n",
    "- academic institutions :\n",
    "  - patents :\n",
    "- governments :\n",
    "  - patents :\n",
    "\n",
    "By looking at these networks, we answer the following questions:\n",
    "- If we take a few different types of companies / government bodies / academic institutions, and look at the network supporting some of their patents, what do these networks look like, in light of the conclusions from Part 1?\n",
    "- Within the same companies, how have their networks evolved between today and the 1990's, if we look at patents similar to those above?\n",
    "- Across companies of the same type, to what extent, if any, will their networks be similar?\n",
    "\n",
    "### Approach\n",
    "\n",
    "We came to the conclusion that the most natural approach again here was to explore the data using maps to visualize the innovation networks. The specific patents which are the starting points for this analysis were chosen manually, using the **[Google Patents](https://patents.google.com/)** database to look for adequate patents to compare. We again made use of the the **Folium** library, though here we thought that the layer control would be more interesting, as we would only be looking at the 4-5 layers of patent citations supporting the chosen patents.\n",
    "\n",
    "We thought about representing the networks using a graph-based approach, using e.g. the Python library **[networkx](https://networkx.github.io/)**, though we felt like this was not adding more information than looking at the distribution of the inventor locations using **Folium**'s heat map plugin.\n",
    "\n",
    "For both parts 1 and 2, while the **data gathering** and **data preprocessing** were done mostly in parallel and in an interative fashion, for simplicity we nonetheless start by presenting the data gathering part and we then present the data preprocessing, both as in their final iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatentsView Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database offers a wide range of features for all patents since 1976, which can be extracted through their API. \n",
    "\n",
    "The most relevant documentation can be found here:\n",
    "- [Query Language Documentation](http://www.patentsview.org/api/query-language.html)\n",
    "- [Field List](http://www.patentsview.org/api/patent.html)\n",
    "\n",
    "For each research question, we came up with a list of required output **fields** which the API calls needed to return, as well as a list of input **filters** that limit the amount of extra pre-processing we had to do, while at the same time providing us with all the information necessary for us to cover the topics listed in the first section.\n",
    "\n",
    "The complete list of **fields** is as follows:\n",
    "- **Part 1**. For each patent in a given timeframe, we need:\n",
    "  - `cited_patent_number`: Patent number of the cited patents.\n",
    "  - `inventor_latitude`: Latitude of all the inventors as listed on the selected patent.\n",
    "  - `inventor_longitude`: Longitude of all the inventors as listed on the selected patent.\n",
    "  - `patent_type`: Category of patent (see below).\n",
    "  - `assignee_organization`: Organization name, if assignee is organization.\n",
    "  - `assignee_type`: Classification of assignee (see below).\n",
    "\n",
    "- For **Part 2**, the list is the same, with the exception of the last two items, which are not needed for the second part. \n",
    "\n",
    "The `assignee_type` field allows us to have a good picture of the typical patent rights holder. The `assignee_type` categories are as follows:\n",
    "- '2': US company or corporation\n",
    "- '3': foreign company or corporation\n",
    "- '4': US individual\n",
    "- '5': foreign individual\n",
    "- '6': US government\n",
    "- '7': foreign government\n",
    "- '8': country government\n",
    "- '9': US state governement\n",
    "- '1x': part interest\n",
    "\n",
    "As well, the reason for including the `patent_type` field is that we want to be able to distinguish between major patent categories:\n",
    "- 'Defensive Publication': \"... an intellectual property strategy used to prevent another party from obtaining a patent on a product, apparatus or method for instance.\" ( [wikipedia](https://en.wikipedia.org/wiki/Defensive_publication) )\n",
    "- 'Design': \"... legal protection granted to the ornamental design of a functional item\" ( [wikipedia](https://en.wikipedia.org/wiki/Design_patent) )\n",
    "- 'Plant': covering any \"new variety of plant\" ( [wikipedia](https://en.wikipedia.org/wiki/Plant_breeders'_rights) )\n",
    "- 'Reissue': correction of \"a significant error in an already issued patent\" ( [uslegal](https://definitions.uslegal.com/r/reissue-patent/) )\n",
    "- 'Statutory Invention Registration': \"for publishing patent applications on which they no longer felt they could get patents\" ( [wikipedia](https://en.wikipedia.org/wiki/United_States_Statutory_Invention_Registration) )\n",
    "- 'Utility': patent for a \"useful\" patent ( [wikipedia](https://en.wikipedia.org/wiki/Utility_(patent)) )\n",
    "\n",
    "**Utility patents** are the most relevant for us. They are patents protecting \"any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement thereof\" ( [U.S. Code § 101](https://www.law.cornell.edu/uscode/text/35/101) ) We do chose to exclude the **reissue** patent type from our results, as they are not truly innovations, but only corrections on already issued patents. This category is thus omitted directly when calling the API.\n",
    "\n",
    "We chose to query for the **latitudes** and **longitudes** instead of the location in the format city-state-country, as the former data are more useful for visualization purposes. Furthermore, during our preliminary data analysis, the data in the city-state-country format was not uniform (i.e., some cities were named in full, while others were abbreviated in different ways). On the other hand, the latitudes and longitudes data is uniform, and the missing data was also easier to clean than with names format.\n",
    "\n",
    "We also needed to be able to query for patents based on the following **filters**:\n",
    "- `patent_number`: US Patent number, as assigned by USPTO.\n",
    "- `app_date`: Date the patent application was filed (filing date)\n",
    "\n",
    "For the purposes of situating in time the patent data we have, we chose to consider the date at which the patent application was filed, instead of the date at which it was granted. The reasoning behind this choice is that at the time of the patent application, the innovation supporting it already exists. So while using the application date has reduced the amount of most-recent data (post 2014) we can work with, in our opinion it paints a more vivid picture of innovation. Furthermore, as our analysis is performed on data spanning a almost 3 decades, we're confident this choice is not detremental to our story. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the PatentsView API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The maximum number of results per query through the PatentsView API is 10,000 per page, capped at 10 pages.** (In order to avoid hitting the limit, as a rule of thumb, if we are querying for all patent applications in a given date range, we need to keep the date range to about quarter of a year.) So while the PatentsView API made it easy to extract data, the usage limits meant we had to implement some functions to automate the incremental extraction and saving of all the data we needed.\n",
    "\n",
    "The following implemented functions can be found in the **[pipeline.py](https://github.com/cmdavid-epfl/Project/blob/master/pipeline.py)** module.\n",
    "\n",
    "- **patentsviewAPI**: puts together the query string, the output fields string and the options string, and then extracts and saves the data returned by the PatentsView API in json format. The following functions are called by **patentsviewAPI**:\n",
    "  - **query**: Forms query filters string to pass into **get_data**.\n",
    "  - **get_data** : Extract and save data from the PatentsView API.\n",
    "  \n",
    "The saved json data is of the following format:\n",
    "\n",
    "- page number in format '1', '2', ...\n",
    "  - 'patents': list of patents in page. For each patent:\n",
    "    - 'patent_type'\n",
    "    - 'inventors' : list of inventors listed for the patent. For each inventor:\n",
    "      - 'inventor_key_id'\n",
    "      - 'inventor_latitude'\n",
    "      - 'inventor_longitude'\n",
    "    - 'assignees': list of assignees listed for the patent. For each assignee:\n",
    "      - 'assignee_key_id'\n",
    "      - 'assignee_organization'\n",
    "      - 'assignee_type'\n",
    "    - 'cited_patents' : list of other patents cited by the current patent. For each cited patent:\n",
    "      - 'cited_patent_number'\n",
    "  - 'count': number of results in the page\n",
    "  - 'total_patent_count': total number of patents referenced in the results  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.\n",
    "\n",
    "The following functions in the **pipeline** module are specifically for preprocessing the data required for Part 1:\n",
    "- **load_data**: converts the saved jsondata from the PatentsView API to the format that is most useful in answering the research topics stated in Part 1, by calling on the following functions:\n",
    "  - **get_full_year_data**: Fetches data for a full year, one quarter at a time, to deal with the PatentsView limits.\n",
    "  - **preprocess_data**: Preprocesses saved json data from file to the format used for the data analysis.\n",
    "  \n",
    "- **get_ts**: Extracts time series data from the dataset. The extracted time series are as follows:\n",
    "  - Number of patent applications for each year\n",
    "  - Number of inventors listed in patent applications in each year\n",
    "  - Number of patents cited in patent applications filed in each year\n",
    "  - Number of utility patent applications in each year\n",
    "  - Number of design patent applications in each year\n",
    "  - Number of individuals listed as assignees in patent applications in each year\n",
    "\n",
    "- **get_all_locations**: Returns list of locations and the number of inventors at each location for the given data, in the format required by the Folium heatmap plugin.\n",
    "\n",
    "- **get_top_k_locations**: Returns list of locations and the number of inventors at each location, considering only the data from the top k assignees, ranked by number of patent applications.\n",
    "\n",
    "- **get_assignee_ts**: Returns the time series of the number of inventors for the specified assignees\n",
    "\n",
    "The proprocessing is straightforward, as the PatentsView API returns data in json format. The preprocessed data (output of **load_data**) has the following structure:\n",
    "- for each YEAR\n",
    "  - dataframe: proportion of patents in each patent type.\n",
    "  - dataframe: unique list of all inventor locations. For each inventor location : the count of the number of inventors listed in patent applications that were based at that location at the time of the application.\n",
    "  - int: total number of patent applications.\n",
    "  - int: total number of citations made in all the patent applications.\n",
    "  - int: total number of inventors listed in the patent applications.\n",
    "  - dataframe: information on assignees. For each unique assignee:\n",
    "    - name of the assignee, if an organization\n",
    "    - type of the assignee (see **PatentsView Database** section, above)\n",
    "    - counter containing the number of inventors based in each location\n",
    "    - number of patent applications\n",
    "    - number of citations made in patent applications\n",
    "    \n",
    "\n",
    "### Missing Data and Inconsistencies\n",
    "\n",
    "The **preprocess_data** function takes care of the missing data and inconsistencies that were found during the data exploration phase. These particularities are summarized as follows.\n",
    "\n",
    "- We discard the data belonging to assignees which have no `assignee_id` attributed. \n",
    "- We discard the data with NaN as `assignee_type`. \n",
    "- We do not count the cited patents which have no corresponding patent_number, which are a negligeable amount.\n",
    "- We discard data which have either None or '0.1' in either `inventor_latitude` or `inventor_longitude`, as this data is useless for the visualizations.\n",
    "\n",
    "We show below that the amount is negligeable, as compared to the total amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required imports for loading the data for Part 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import load_data, get_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define local data folder and data year range.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_PATH = '/media/dcm/HDD/ADA_DATA'\n",
    "MIN_YEAR = 1990\n",
    "MAX_YEAR = 2016\n",
    "year_range = range(MIN_YEAR,MAX_YEAR + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the full dataset. As the data is already all on disk, the data preprocessing takes less than an hour to complete. **Running this next line for the full time range (1990-2016), if no data is yet saved to disk, will take a few hours.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dcm/HDD/ADA_DATA 1990q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1990q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1990q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1990q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1990q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1990q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1990q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1990q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1991q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1991q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1991q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1991q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1991q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1991q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1991q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1991q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1992q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1992q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1992q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1992q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1992q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1992q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1992q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1992q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1993q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1993q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1993q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1993q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1993q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1993q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1993q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1993q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1994q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1994q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1994q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1994q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1994q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1994q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1994q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1994q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1995q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1995q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1995q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1995q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1995q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1995q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1995q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1995q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1996q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1996q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1996q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1996q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1996q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1996q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1996q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1996q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1997q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1997q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1997q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1997q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1997q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1997q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1997q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1997q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1998q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1998q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1998q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1998q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1998q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1998q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1998q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1998q4.json\n",
      "/media/dcm/HDD/ADA_DATA 1999q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1999q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1999q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 1999q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/1999q1.json\n",
      "/media/dcm/HDD/ADA_DATA/1999q2.json\n",
      "/media/dcm/HDD/ADA_DATA/1999q3.json\n",
      "/media/dcm/HDD/ADA_DATA/1999q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2000q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2000q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2000q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2000q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2000q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2000q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2000q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2000q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2001q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2001q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2001q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2001q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2001q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2001q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2001q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2001q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2002q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2002q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2002q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2002q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2002q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2002q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2002q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2002q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2003q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2003q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2003q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2003q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2003q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2003q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2003q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2003q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2004q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2004q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2004q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2004q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2004q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2004q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2004q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2004q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2005q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2005q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2005q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2005q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2005q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2005q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2005q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2005q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2006q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2006q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2006q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2006q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2006q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2006q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2006q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2006q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2007q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2007q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2007q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2007q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2007q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2007q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2007q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2007q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2008q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2008q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2008q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2008q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2008q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2008q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2008q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2008q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2009q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2009q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2009q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2009q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2009q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2009q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2009q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2009q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2010q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2010q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2010q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2010q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2010q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2010q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2010q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2010q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2011q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2011q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2011q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2011q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2011q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2011q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2011q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2011q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2012q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2012q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2012q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2012q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2012q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2012q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2012q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2012q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2013q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2013q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2013q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2013q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2013q1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dcm/HDD/ADA_DATA/2013q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2013q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2013q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2014q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2014q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2014q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2014q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2014q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2014q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2014q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2014q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2015q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2015q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2015q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2015q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2015q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2015q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2015q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2015q4.json\n",
      "/media/dcm/HDD/ADA_DATA 2016q1\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2016q2\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2016q3\n",
      "already on file\n",
      "/media/dcm/HDD/ADA_DATA 2016q4\n",
      "already on file\n",
      "loading data from disk\n",
      "/media/dcm/HDD/ADA_DATA/2016q1.json\n",
      "/media/dcm/HDD/ADA_DATA/2016q2.json\n",
      "/media/dcm/HDD/ADA_DATA/2016q3.json\n",
      "/media/dcm/HDD/ADA_DATA/2016q4.json\n"
     ]
    }
   ],
   "source": [
    "full_year_data = load_data(year_range, MY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_year_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_by_patent_type', 'locations', 'num_patents', 'num_citations', 'num_inventors', 'assignees', 'discarded'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_year_data['1990'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(35.6895, 139.692)</th>\n",
       "      <td>8211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(35.4437, 139.638)</th>\n",
       "      <td>4507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(37.5833, 139.917)</th>\n",
       "      <td>3699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(34.6971, 135.498)</th>\n",
       "      <td>2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(35.5298, 139.702)</th>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "index                   \n",
       "(35.6895, 139.692)  8211\n",
       "(35.4437, 139.638)  4507\n",
       "(37.5833, 139.917)  3699\n",
       "(34.6971, 135.498)  2682\n",
       "(35.5298, 139.702)  1879"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_year_data['1990']['locations'].sort_values(by=0, ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>type</th>\n",
       "      <th>inventors_loc</th>\n",
       "      <th>patents</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338389</th>\n",
       "      <td>Kabushiki Kaisha Toshiba</td>\n",
       "      <td>3</td>\n",
       "      <td>{(35.1814, 136.906): 4, (35.6895, 139.692): 21...</td>\n",
       "      <td>1121</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164304</th>\n",
       "      <td>Canon Kabushiki Kaisha</td>\n",
       "      <td>3</td>\n",
       "      <td>{(35.5298, 139.702): 141, (35.4437, 139.638): ...</td>\n",
       "      <td>1055</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299786</th>\n",
       "      <td>Hitachi, Ltd.</td>\n",
       "      <td>3</td>\n",
       "      <td>{(35.7225, 140.1): 3, (43.9333, 143.717): 6, (...</td>\n",
       "      <td>1038</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222962</th>\n",
       "      <td>Eastman Kodak Company</td>\n",
       "      <td>2</td>\n",
       "      <td>{(43.0987, -77.4419): 38, (42.9981, -78.1875):...</td>\n",
       "      <td>919</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63181</th>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>2</td>\n",
       "      <td>{(34.8667, 134.633): 2, (41.584, -73.8087): 8,...</td>\n",
       "      <td>899</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       organization type  \\\n",
       "338389                     Kabushiki Kaisha Toshiba    3   \n",
       "164304                       Canon Kabushiki Kaisha    3   \n",
       "299786                                Hitachi, Ltd.    3   \n",
       "222962                        Eastman Kodak Company    2   \n",
       "63181   International Business Machines Corporation    2   \n",
       "\n",
       "                                            inventors_loc  patents  citations  \n",
       "338389  {(35.1814, 136.906): 4, (35.6895, 139.692): 21...     1121       1097  \n",
       "164304  {(35.5298, 139.702): 141, (35.4437, 139.638): ...     1055       1047  \n",
       "299786  {(35.7225, 140.1): 3, (43.9333, 143.717): 6, (...     1038       1010  \n",
       "222962  {(43.0987, -77.4419): 38, (42.9981, -78.1875):...      919        907  \n",
       "63181   {(34.8667, 134.633): 2, (41.584, -73.8087): 8,...      899        887  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_year_data['1990']['assignees'].sort_values(by='patents', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verifying data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_patents = 0\n",
    "discarded_citations = 0\n",
    "discarded_assignees = 0\n",
    "discarded_inventors = 0\n",
    "\n",
    "for year in year_range:\n",
    "    discarded = full_year_data[str(year)]['discarded']\n",
    "    discarded_patents += discarded[0]\n",
    "    discarded_citations += discarded[1]\n",
    "    discarded_assignees += discarded[2]\n",
    "    discarded_inventors += discarded[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12842, 298046, 122, 83454)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discarded_patents, discarded_citations, discarded_assignees, discarded_inventors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the time series graphs in the data story, we conclude that these numbers are negligeable compared to the total amount of data. To be sure, we need to take into account that the above numbers are for all the years, so if one same assignee is discarded each year, it would be counted 27 times. In the data we do use, we have around 150k patents each year, 1.25M citations each year, 20k assignees and 300k inventors. All these numbers multiplied by 27 years make the above numbers negligeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.\n",
    "\n",
    "The following functions in the **pipeline** module are specifically for preprocessing the data required for Part 2:\n",
    "- **load_layers_data**: Loads data from disk and converts the required data from json to dataframe.\n",
    "  - **get_layers_data**: Fetches all data, one layer at a time.\n",
    "    - **get_cited_patents_data**: Fetches the data for the given list of patent_numbers from the PatentsView API.\n",
    "    - **preprocess_layer_data**: Preprocesses saved json data from file to the format used for the data analysis.\n",
    "    \n",
    "The preprocessed data (output of **load_layers_data**) has the following structure:\n",
    "- for each LAYER:\n",
    "  - a list of the patents cited by the patents in that layer\n",
    "  - a unique list of inventors and their locations for the patents in that layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import load_layers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_example_data = load_layers_data(filename = 'Apple', patent_number = ['9430098'], layers = 4, data_dir = MY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_example_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_example_data['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_example_data['0']['cited_patents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_example_data['0']['inventors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.\n",
    "\n",
    "The following functions in the **visualizations** module are specifically for Part 1:\n",
    "- **get_html**: Produces HTML rendering of Folium map of the distribution of the inventors for the given type (All Assignees, All or top K US Assignees, or All or top K Non-US Assignees) for the given year, and saves it to working directory.\n",
    "  - If viz is 'All' and K is None, produces a map showing the locations of all inventors\n",
    "  - If viz is 'All' and K is k, produces a map showing the locations of inventors for the top k assignees, as well as csv file containing the list of of those assignees and their number of patents, and returns the total number of inventors for those assignees\n",
    "  - If viz is 'US Assignees' or 'Non-US Assignees', K is not optional\n",
    "  \n",
    "- **get_timeseries_fig**: Produces a figure with the following time series plots and saves to working directory:\n",
    "    - Number of utility patents vs design patents vs other patents\n",
    "    - Total number of inventors\n",
    "    - Number of inventors for the top K Non-US/US Assignees\n",
    "    - Total number of Citations\n",
    "    - Total number of individuals as assignees\n",
    "\n",
    "- **get_assignees_plot**: Produces a figure comparing the time series plots of the number of inventors for two lists of assignees, and saves to working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations import get_html, get_timeseries_fig, get_assignees_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines produce the HTML figures for the maps in Part 1. In the data story, only the first map is a Leaflet, and the rest are timelapse GIFs which were manually created from these HTML files. To create these timelapses, we first converted the HTML files to PNG using **[image-online-convert](https://image.online-convert.com/convert-to-png)** (which was the only good-quality free service that did not impose any limits for this type of job). We then used the open-source image editor **[GIMP](https://www.gimp.org/)** to create a timelapse of these images with the year shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World View\n",
    "for year in year_range:\n",
    "    get_html(full_year_data,'All',year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom on Asia\n",
    "for year in year_range:\n",
    "    get_html(full_year_data,'All',year, zoom_on = (25,120,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom on Europe\n",
    "for year in year_range:\n",
    "    get_html(full_year_data,'All',year, zoom_on = (53,18,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom on US\n",
    "for year in year_range:\n",
    "    get_html(full_year_data,'All',year, zoom_on = (40,-90,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World View, Top 10 Assignees US and Non-US\n",
    "num_inventors_top10_us = []\n",
    "num_inventors_top10_nonus = []\n",
    "\n",
    "for year in year_range:\n",
    "    num_inventors_top10_us.append(get_html(full_year_data,'US Assignees',year, k = 10))\n",
    "    num_inventors_top10_nonus.append(get_html(full_year_data,'Non-US Assignees',year, k = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series figure\n",
    "get_timeseries_fig(full_year_data, year_range, num_inventors_top10_us, num_inventors_top10_nonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the table containing the names of the top 10 assignees in for each year, we manually copy-pasted the lists for each year which is produced by **get_html()**, when passing an argument for K, into a single CSV file and we then converted that file to HTML using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top assignees tables\n",
    "text_file = open(\"top_us_table.html\", \"w\")\n",
    "text_file.write(pd.read_csv(MY_PATH + '/Results/Top10_US.csv', index_col=0).to_html(index = False, \n",
    "                                                                                    col_space=200, \n",
    "                                                                                    justify = 'left'))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"top_nonus_table.html\", \"w\")\n",
    "text_file.write(pd.read_csv(MY_PATH + '/Results/Top10_NonUS.csv', index_col=0).to_html(index = False, \n",
    "                                                                                    col_space=200, \n",
    "                                                                                    justify = 'left'))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last plot of Part 1, we arbitralily chose a handful of the top assignees to plot the evolution of their number of inventors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolution in number of inventors for top assignees plot\n",
    "assignees_us = ['Intel Corporation', 'Amazon Technologies, Inc.','International Business Machines Corporation',\n",
    "                'Google Inc.', 'General Electric Company', 'QUALCOMM Incorporated']\n",
    "assignees_nonus = ['Samsung Electronics Co., Ltd.', 'Canon Kabushiki Kaisha', 'Sony Côrporation',\n",
    "                   'Taiwan Semiconductor Manufacturing Company, Ltd.','Hon Hai Precision Industry Co., Ltd.',\n",
    "                   'LG Electronics Inc.','Huawei Technologies Co., Ltd.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_assignees_plot(full_year_data, assignees_us, assignees_nonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.\n",
    "\n",
    "The following functions in the **visualizations** module are specifically for Part 2:\n",
    "- **save_layers**: Produce HTML rendering of Folium map with or without layer control.\n",
    "  - If layered is True, then it produces a single HTML file with each Leaflet layer representing the locations of the inventors in each layer of innovators\n",
    "  - If layered is False, then it produces one HTML file for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations import save_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_layers(apple_example_data, 'apple', zoom_on = None, layered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
