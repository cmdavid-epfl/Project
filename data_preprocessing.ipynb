{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring out the relevant data for each research question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1/ How can we best identify and visualize different geographical innovation networks? Can we estimate the number of people in such networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first part, we need the following output **fields**:\n",
    "- `patent_number`: US Patent number, as assigned by USPTO.\n",
    "- `assignee_latitude`: Latitude for assignee's location as listed on the patent.\n",
    "- `assignee_longitude`: Longitude for assignee's location a listed on the patent.\n",
    "- `cited_patent_number`: Patent number of cited patent.\n",
    "- `inventor_latitude`: Latitude of inventor's as listed on the selected patent.\n",
    "- `inventor_longitude`: Longitude of inventor's city as listed on the selected patent.\n",
    "- `inventor_lastknown_latitude`: Latitude of inventor's city as of their most recent patent grant date.\n",
    "- `inventor_lastknown_longitude`: Longitude of inventor's city as of their most recent patent grant date.\n",
    "- `patent_type`: Category of patent (see below).\n",
    "\n",
    "We chose to query for the latitudes and longitudes instead of for the location in the format city-state-country, as the former data are more useful for visualization purposes. Furthermore, during our preliminary data analysis, the data in the city-state-country format was not uniform (i.e., some cities were named in full, while others were abbreviated in different ways). On the other hand, the latitudes and longitudes data is uniform, and the missing data is also easier to clean than with the other format.\n",
    "\n",
    "The reason for including the `patent_type` field is that we want to be able to distinguish between major patent categories, i.e. (this will be detailed further)\n",
    "- 'Defensive Publication'\n",
    "- 'Design'\n",
    "- 'Plant'\n",
    "- 'Reissue'\n",
    "- 'Statutory Invention Registration'\n",
    "- 'Utility'\n",
    "\n",
    "We will also need to be able to query for patents based on the following **filters**:\n",
    "- `patent_number`: US Patent number, as assigned by USPTO.\n",
    "- `app_date`: Date the patent application was filed (filing date)\n",
    "\n",
    "We the purposes of situating in time the patent data we have, we chose to consider the date at which the patent application was filed, instead of the date at which it was granted. The reasoning behind this choice is that at the time of the patent application, the innovation supporting the it already exists. So while using the application date will most probably reduced the amount of most-recent data we can work with, in our opinion it will paint a more vivid picture of innovation. Furthermore, as our analysis is performed on data spanning a few decades, we're confident this choice will not be detremental to our story. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1/ If we then take a few examples of different types of companies and look at the network of patents supporting their own patents, will these networks match up with the former innovation networks, or will they be more self-contained? In the latter case, can we estimate the number of people that make up these networks? Are these innovation networks concentrated around specific areas, or are they spread out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does not require any extra fields than in the first case. On the other hand, it will be necessary for us to be able to query for the patents owned by specific companies. To this end, we need the following **filter**:\n",
    "- `assignee_organization`: Organization name, if assignee is organization\n",
    "\n",
    "The process we will follow in order to answer this question is as follows:\n",
    "- Settle on a few examples of companies operating in the same industry (e.g., Facebook, Twitter, Snapchat or Apple, Samsung, Huawei).\n",
    "- For each of the chosen companies, identify the patents they held a given point in time\n",
    "- Identify the network of innovators behind these patents\n",
    "- Visualize the networks for each of the companies\n",
    "- Analyze the results - see Q.1.2\n",
    "\n",
    "For this question, as well as the following ones, we will also try to design and implement an interactive way to visualize the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2/ Do similar companies use the same knowledge bases to innovate? For example, if we look at different social networking companies, will the networks supporting their patents be distinct? Will a given companies patents mostly cite their own previous patents, or will they tap outside innovation networks? On what scale? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features necessary to answer these questions have been covered above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3/ What about if we look at university/academic knowledge bases and compare them with those of the companies analyzed above?\n",
    "\n",
    "### Q1.4/ What about governmental or non-governmental organizations, or international agencies?\n",
    "\n",
    "### Q1.5/ How have the innovation networks identified above evolved through time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process to be followed to answer these questions is similar to the process for **Q1.1**, with the exception that we need to be able to identify which patents belong to companies, organizations and governmental entities. To this end, we add the following output **fields** to our search queries:\n",
    "- `assignee_type`: Classification of assignee.\n",
    "\n",
    "The assignee classes are as follows:\n",
    "- '2': US company or corporation\n",
    "- '3': foreign company or corporation\n",
    "- '4': US individual\n",
    "- '5': foreign individual\n",
    "- '6': US government\n",
    "- '7': foreign government\n",
    "- '8': country government\n",
    "- '9': US state governement\n",
    "- '1x': part interest\n",
    "\n",
    "We will also need the following extra output **field**:\n",
    "- `app_date`: Date the patent application was filed (filing date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2/ What does the typical patent-holder look like today (Corporation, Universities, Governments, Individuals), and how has that evolved throughout time / geographies?\n",
    "\n",
    "### Q2.1/  Is a migration of innovators through time visible in the data, e.g. a convergence towards certain innovation centers?\n",
    "\n",
    "### Q2.2 / How has the number of assignees and inventors evolved through for different patent types? Are there significant differences in these numbers between different geographies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features necessary to answer these questions have been covered above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering and pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **pipeline.py** file contains the functions used to prepare the data for our analysis. The functions that are used at this level are:\n",
    "- The **patentsviewAPI()** function puts together the query string, the output fields string and the options string, and then extracts and saves the data returned by the PatentsView API in json format. The saved json data is of the following format (if there are no extra output fields added to the query):\n",
    "\n",
    "\n",
    "    - page number in format '1', '2', ...\n",
    "      - 'patents': list of patents in page. For each patent:\n",
    "        - 'patent_number'\n",
    "        - 'patent_type'\n",
    "        - 'inventors' : list of inventors listed for the patent. For each inventor:\n",
    "          - 'inventor_latitude'\n",
    "          - 'inventor_longitude'\n",
    "          - 'inventor_lastknown_latitude'\n",
    "          - 'inventor_lastknown_longitude'\n",
    "          - 'inventor_key_id'\n",
    "        - 'assignees': list of assignees listed for the patent. For each assignee:\n",
    "          - 'assignee_latitude'\n",
    "          - 'assignee_longitude'\n",
    "          - 'assignee_organization'\n",
    "          - 'assignee_type'\n",
    "          - 'assignee_key_id'\n",
    "        - 'applications'\n",
    "          - 'app_date'\n",
    "          - 'app_id'\n",
    "        - 'cited_patents' : list of other patents cited by the current patent. For each cited patent:\n",
    "          - 'cited_patent_number'\n",
    "      - 'count': number of results in the page\n",
    "      - 'total_patent_count': total number of patents referenced in the results\n",
    "\n",
    "\n",
    "- The **json_to_pandas()** function converts the saved json data from the PatentsView API to the format that is most convient for us - a set containing the following Pandas DataFrames:\n",
    "  - `date`: associates a patent_number their application date.\n",
    "  - `patent_type`: the number of patents in each patent_type category.\n",
    "  - `assignee_type`: the number of patents in each assignee_type category.\n",
    "  - `assignee_organization`: the number of patents belonging to each organization in the dataset.\n",
    "  - `cited_patent_number`: the number of citations for each patent cited by a patent in the dataset.\n",
    "  - `inventor_location`: inventor locations as stated in the patent application, indexed by patent_number.\n",
    "  - `inventor_lastknown_location`: inventor locations as stated in the their most recent patent, indexed by patent number.\n",
    "  - `assignee_location`: assignee locations as stated in the patent application, indexed by patent number.\n",
    "  \n",
    "  This function will make analyzing the 'raw' data more straightforward. Using this function to analyze the query results, we will then be able to specify the data cleaning process that is needed.\n",
    "  \n",
    "**As the maximum number of results per query is 10,000 per page, capped at 10 pages, in order to avoid hitting the limit, as a rule of thumb, if we are querying for all patent applications in a given date range, we need to keep the date range to about quarter of a year.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of analysis on a sample of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import patentsviewAPI, json_to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = patentsviewAPI(filename = '2015_q1', filepath = 'data',\n",
    "                          app_date_from = '\"2015-01-01\"', app_date_to = '\"2015-03-31\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_to_pandas('data/2015_q1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date', 'patent_type', 'assignee_type', 'assignee_organization', 'cited_patent_number', 'inventor_location', 'inventor_lastknown_location', 'assignee_location'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `date` dataframe. There should not be any inconsistencies here, as our query was based on the dates, so inconsistent dates would not have been returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'].min().values[0], data['date'].max().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['date'].values == None), sum(data['date'].values == float('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `patent_type` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>utility</th>\n",
       "      <td>47695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design</th>\n",
       "      <td>7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plant</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reissue</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "utility  47695\n",
       "design    7218\n",
       "plant      251\n",
       "reissue     94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['patent_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility patents** are the most relevant for us. They are patents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `assignee_type` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['assignee_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the NaNs count in the `assignee_type` dataframe is negligeable as compared to the total count of assignees, there is an issue: assignee_types 4 and 5 refer to, respectively, US and foreign individuals. The total number of individuals assignees is thus much smaller than the NaN assignees count. Before removing the NaN values, we will need to investigate further what they may represent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `assignee_organization` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['assignee_organization'].head(10)), print(data['assignee_organization'].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assignee in data['assignee_organization'].index.values[1:]:\n",
    "    if 'sony' in assignee.lower():\n",
    "        print(assignee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN count is refers should normally correspond to the total number of indiviuals assignee_type. In this case, though, we notice that it corresponds almost perfectly to the sum of the individual assignees count and NaN counts in the `assignee_type` dataframe.\n",
    "\n",
    "While the organization names are definitely not in a standardized format, this will not be a problem, as we can simply use the list we obtain from querying for dates to get a list of the names used in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['assignee_type']['count'].iloc[2:5]), sum(data['assignee_organization'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `cited_patent_number` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['cited_patent_number'].head(10)), print(data['cited_patent_number'].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['cited_patent_number']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cited_patent_number'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN count here refers to the number of patent citations by the patents in our dataset which do not have a patent number. This is to say that the NaN count is an upper bound on the number of cited patents with no corresponding patent number. As the number of total cited patents is almost 100 times larger than the NaN count, we judge that we can safely disregard them and have them be skipped in the data cleaning process. Otherwise, we see that all entries are numeric, which suggests that the format is entirely uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `inventor_location` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inventor_location'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do will be to convert the latitudes and longitudes from objects to floats, while performing the data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inventor_location'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['assignee_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['assignee_location'].values == None), sum(data['assignee_location'].values == float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['assignee_location'].values == '0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major issue here is that almost 10% of the latitude and longitude data is either ('None','None') or ('0.1','0.1'). As our goal is to come up with a way to 'visualize' the dynamics of innovation, we need to discard this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `inventor_location` and `inventor_lastknown_location` dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inventor_location'].dtypes, data['inventor_lastknown_location'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['inventor_location'].values == None), sum(data['inventor_location'].values == float('nan')), sum(data['inventor_location'].values == '0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data['inventor_lastknown_location'].values == None), sum(data['inventor_lastknown_location'].values == float('nan')), sum(data['inventor_lastknown_location'].values == '0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to produce a more in-depth analysis of the  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
